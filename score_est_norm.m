function [grad_est, H_est, grad_est_vec] = score_est_norm(y, theta, DP_param, a, b, N)

% [grad_est, H_est, grad_est_vec] = score_est_norm(y, theta, DP_param, a, b, N)
% 
% This function uses a Monte Carlo integration to approaximately calculate
% the score vectors w.r.t. mu_x and std_x given the observations generated by
%
% Y_t = min(max(a, X_t), b) + Laplace(DP_param), X_t ~ N(mu_x, var_x), t =
% 1,..n
% 
% y, a, b, var_DP must be row vectors.
%
% The output is a matrix whose columns are scores for Y_t
% 
% Sinan Yildirim
% 19.01.2023

mu_x = theta(1);
std_x = theta(2);
L = length(y);

x_par = mu_x + std_x*randn(N, L);
s_par = trunc_lr(x_par, a, b);
log_w = -abs(y - s_par)./DP_param;

% Take the max of the columns
m = max(log_w, [], 1);
log_sum_w_vec = log(sum(exp(log_w - m), 1)) + m;
w = exp(log_w - log_sum_w_vec);

% calculate the gradients wrt the mean and the standard deviation
grad_par_mu = (x_par - mu_x)/(std_x^2);
grad_par_std = (x_par - mu_x).^2/std_x^3 - (1/std_x);

% The matrix of score vectors
grad_est_vec = [sum(grad_par_mu.*w, 1); sum(grad_par_std.*w, 1)];
grad_est = sum(grad_est_vec, 2);

% second derivative
H_est(1, 1) = L/(std_x^2) + sum(sum(((x_par - mu_x).^2/(std_x^4)).*w, 2)) - grad_est(1)^2;

d2l =  3*(x_par - mu_x).^2/std_x^4 - 1/std_x^2;
dl2 =  ((x_par - mu_x).^2/std_x^3 - (1/std_x)).^2;

weighted_d = w.*(d2l + dl2);
H_est(2, 2) = sum(weighted_d(:)) - grad_est(2)^2;